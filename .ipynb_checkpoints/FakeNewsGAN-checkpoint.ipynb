{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras import Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Conv1D, Dropout, Dense, Embedding, Flatten, Reshape, Multiply, Lambda, UpSampling1D, MaxPooling1D, LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Traitement des données</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des deux tables\n",
    "real_news = pd.read_csv(\"./dataset1/True.csv\")\n",
    "fake_news = pd.read_csv(\"./dataset1/Fake.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vrai = 1, faux = 0\n",
    "real_news[\"label\"] = 1\n",
    "fake_news[\"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11812</th>\n",
       "      <td>FAKE NEWS ALERT! CNN Finally Releases ACTUAL P...</td>\n",
       "      <td>As we pointed out throughout the months leadin...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Jan 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>Was Trump’s Tax Evasion Perfectly Legal, As H...</td>\n",
       "      <td>Trump has repeatedly said that all the ways he...</td>\n",
       "      <td>News</td>\n",
       "      <td>October 31, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21642</th>\n",
       "      <td>MORE TRANSPARENCY: CLINTON’S REFUSE TO RELEASE...</td>\n",
       "      <td>Karl Rove is suggesting Hillary suffered brain...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jun 16, 2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8372</th>\n",
       "      <td>This Ego-Killing Jeb Bush Infographic Shows H...</td>\n",
       "      <td>Jeb Bush was supposed to be the adult among th...</td>\n",
       "      <td>News</td>\n",
       "      <td>February 2, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>Legal Scholars Worried Trump Would Break Laws...</td>\n",
       "      <td>What happens when conservative lawyers from th...</td>\n",
       "      <td>News</td>\n",
       "      <td>June 3, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>Whoa! Melania Trump Just Stole A Whole Paragr...</td>\n",
       "      <td>Donald Trump s wife was the headline speaker o...</td>\n",
       "      <td>News</td>\n",
       "      <td>July 19, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16611</th>\n",
       "      <td>French Catalans offer Puigdemont luxury safe-h...</td>\n",
       "      <td>PARIS (Reuters) - French Catalans have a villa...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 24, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16982</th>\n",
       "      <td>Togo forces fire on protesters, seven wounded</td>\n",
       "      <td>LOME (Reuters) - Security forces in Togo fired...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>October 19, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7414</th>\n",
       "      <td>Trump invites Netanyahu to meeting 'at the fir...</td>\n",
       "      <td>JERUSALEM (Reuters) - Israeli Prime Minister B...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 9, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7516</th>\n",
       "      <td>Three U.S. senators ask Mylan for EpiPen milit...</td>\n",
       "      <td>(Reuters) - Three members of the U.S. Senate J...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 7, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "11812  FAKE NEWS ALERT! CNN Finally Releases ACTUAL P...   \n",
       "3988    Was Trump’s Tax Evasion Perfectly Legal, As H...   \n",
       "21642  MORE TRANSPARENCY: CLINTON’S REFUSE TO RELEASE...   \n",
       "8372    This Ego-Killing Jeb Bush Infographic Shows H...   \n",
       "6035    Legal Scholars Worried Trump Would Break Laws...   \n",
       "5420    Whoa! Melania Trump Just Stole A Whole Paragr...   \n",
       "16611  French Catalans offer Puigdemont luxury safe-h...   \n",
       "16982      Togo forces fire on protesters, seven wounded   \n",
       "7414   Trump invites Netanyahu to meeting 'at the fir...   \n",
       "7516   Three U.S. senators ask Mylan for EpiPen milit...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "11812  As we pointed out throughout the months leadin...      politics   \n",
       "3988   Trump has repeatedly said that all the ways he...          News   \n",
       "21642  Karl Rove is suggesting Hillary suffered brain...     left-news   \n",
       "8372   Jeb Bush was supposed to be the adult among th...          News   \n",
       "6035   What happens when conservative lawyers from th...          News   \n",
       "5420   Donald Trump s wife was the headline speaker o...          News   \n",
       "16611  PARIS (Reuters) - French Catalans have a villa...     worldnews   \n",
       "16982  LOME (Reuters) - Security forces in Togo fired...     worldnews   \n",
       "7414   JERUSALEM (Reuters) - Israeli Prime Minister B...  politicsNews   \n",
       "7516   (Reuters) - Three members of the U.S. Senate J...  politicsNews   \n",
       "\n",
       "                    date  label  \n",
       "11812       Jan 25, 2017      0  \n",
       "3988    October 31, 2016      0  \n",
       "21642       Jun 16, 2015      0  \n",
       "8372    February 2, 2016      0  \n",
       "6035        June 3, 2016      0  \n",
       "5420       July 19, 2016      0  \n",
       "16611  October 24, 2017       1  \n",
       "16982  October 19, 2017       1  \n",
       "7414   November 9, 2016       1  \n",
       "7516   November 7, 2016       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# création du dataset complet\n",
    "dataframe = pd.concat([real_news, fake_news])\n",
    "dataframe.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de références : 44898\n",
      "Nombre de fake news : 23481\n",
      "Nombre de vraies news : 21417\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nombre de références : {dataframe.title.count()}\")\n",
    "print(f\"Nombre de fake news : {fake_news.title.count()}\")\n",
    "print(f\"Nombre de vraies news : {real_news.title.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ici on ne s'intéresse qu'au titre et au label\n",
    "del dataframe[\"text\"]\n",
    "del dataframe[\"subject\"]\n",
    "del dataframe[\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16161</th>\n",
       "      <td>RIDICULOUS! CHUCK SCHUMER Wants Republicans To...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20358</th>\n",
       "      <td>SHOCKING PHYSICAL ABUSE REVEALED: Former Secre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14949</th>\n",
       "      <td>Factbox: Divided, rebellious UK parliament tak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12898</th>\n",
       "      <td>WHOA! Medical Expert Watching Debate Exposes A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20859</th>\n",
       "      <td>Factbox: Humanitarian crisis worsens in Bangla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>Warren, Kaine, Castro on Clinton running-mate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9201</th>\n",
       "      <td>Bernie Sanders-style, grassroots effort a like...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11211</th>\n",
       "      <td>Trump fans in Iowa cheer his debate performance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>Trump Gets LEVELED For Literally Thanking Him...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>U.N. rights boss condemns \"spreading hatred th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  label\n",
       "16161  RIDICULOUS! CHUCK SCHUMER Wants Republicans To...      0\n",
       "20358  SHOCKING PHYSICAL ABUSE REVEALED: Former Secre...      0\n",
       "14949  Factbox: Divided, rebellious UK parliament tak...      1\n",
       "12898  WHOA! Medical Expert Watching Debate Exposes A...      0\n",
       "20859  Factbox: Humanitarian crisis worsens in Bangla...      1\n",
       "9054   Warren, Kaine, Castro on Clinton running-mate ...      1\n",
       "9201   Bernie Sanders-style, grassroots effort a like...      1\n",
       "11211    Trump fans in Iowa cheer his debate performance      1\n",
       "3250    Trump Gets LEVELED For Literally Thanking Him...      0\n",
       "448    U.N. rights boss condemns \"spreading hatred th...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nettoyage des données (ponctuations)\n",
    "\n",
    "#stopWords = set(stopwords.words(\"english\"))\n",
    "\n",
    "def cleanText(text):\n",
    "    forbidden = {\",\",\"@\",\";\",\"/\",\"-\",\":\",\".\",\"!\",\"?\", \"#\",\"\\\"\",\"(\",\")\",\"\\'\",\"’\",\"‘\",\"–\",\".\",\"&\"}\n",
    "    res = str(text)\n",
    "    if res != None:\n",
    "        for elm in forbidden:\n",
    "            res = res.replace(elm, \"\")\n",
    "    if len(res.split()) >= 30:\n",
    "        res = \" \".join(res.split()[0:30])\n",
    "    if res != None:\n",
    "        for elm in forbidden:\n",
    "            res = res.replace(\"  \", \" \")\n",
    "    return res\n",
    "\n",
    "#dataframe[\"title\"] = dataframe[\"title\"].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        As U.S. budget fight looms, Republicans flip t...\n",
       "1        U.S. military to accept transgender recruits o...\n",
       "2        Senior U.S. Republican senator: 'Let Mr. Muell...\n",
       "3        FBI Russia probe helped by Australian diplomat...\n",
       "4        Trump wants Postal Service to charge 'much mor...\n",
       "                               ...                        \n",
       "23476    McPain: John McCain Furious That Iran Treated ...\n",
       "23477    JUSTICE? Yahoo Settles E-mail Privacy Class-ac...\n",
       "23478    Sunnistan: US and Allied ‘Safe Zone’ Plan to T...\n",
       "23479    How to Blow $700 Million: Al Jazeera America F...\n",
       "23480    10 U.S. Navy Sailors Held by Iranian Military ...\n",
       "Name: title, Length: 44898, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données d'entrainement : 40408\n",
      "Données de test : 4490\n"
     ]
    }
   ],
   "source": [
    "# on sépare les données en données d'entraînement et données de test (80% et 20%)\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataframe[\"title\"], dataframe[\"label\"], test_size=0.10, random_state = 42)\n",
    "print(f\"Données d'entrainement : {len(x_train)}\")\n",
    "print(f\"Données de test : {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2000 # taille max du vocab\n",
    "maxlen = 16 # taille max de séquence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorisation naïve en \"one-hot\"\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(dataframe[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorisation des données d'entraînement\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "#x_train = tokenizer.sequences_to_matrix(x_train)\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_oneHotSentence(sentence, maxfeatures):\n",
    "    oneHotSentence = []\n",
    "    for word in sentence:\n",
    "        oneHotWord = [0 for _ in range(maxfeatures)]\n",
    "        oneHotWord[word] = 1\n",
    "        oneHotSentence.append(oneHotWord)\n",
    "    return oneHotSentence\n",
    "\n",
    "def to_oneHotCorpus(corpus, maxfeatures):\n",
    "    oneHotCorpus = []\n",
    "    for sentence in corpus:\n",
    "        oneHotCorpus.append(to_oneHotSentence(sentence, maxfeatures))\n",
    "    return np.array(oneHotCorpus)\n",
    "\n",
    "def from_oneHotWord(oneHotWord):\n",
    "    for i in range(len(oneHotWord)):\n",
    "        if oneHotWord[i] > 0:\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "def from_oneHotSentence(oneHotSentence):\n",
    "    sentence = []\n",
    "    for oneHotWord in oneHotSentence:\n",
    "        sentence.append(from_oneHotWord(oneHotWord))\n",
    "    return sentence\n",
    "        \n",
    "def from_oneHotCorpus(oneHotCorpus):\n",
    "    return np.argmax(oneHotCorpus, axis=2)\n",
    "\n",
    "\n",
    "#x_train = to_oneHotCorpus(x_train, max_features)\n",
    "#x_train = from_oneHotCorpus(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorisation des données de test\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "#x_test = to_oneHotCorpus(x_test, max_features)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "nb_epochs = 20\n",
    "embedded_dim = 100\n",
    "latent_dim = 100\n",
    "kernel_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, nbpoints):\n",
    "    return np.random.uniform(0, 1, size=[nbpoints, latent_dim])\n",
    "\n",
    "def getLatentSamples(latent_dim, n):\n",
    "    labels = np.zeros(shape=n)\n",
    "    samples = generate_latent_points(latent_dim, n)\n",
    "    \n",
    "    return samples, labels\n",
    "\n",
    "def getFakeSamples(generator, latent_dim, n):\n",
    "    labels = np.ones(shape=n)\n",
    "    \n",
    "    latent_points = generate_latent_points(latent_dim, n)\n",
    "    samples = generator.predict(latent_points)\n",
    "    \n",
    "    return samples, labels\n",
    "\n",
    "def getRealSamples(X, Y, n):\n",
    "    random_indices = np.random.randint(0, X.shape[0], n)\n",
    "\n",
    "    samples = X[random_indices]\n",
    "    labels = Y[random_indices]\n",
    "    \n",
    "    return samples, labels\n",
    "\n",
    "def generateFakeNews(model, n):\n",
    "    few_points = generate_latent_points(latent_dim, n)\n",
    "    predictions = generator.predict(few_points)\n",
    "    fake_news = np.round(predictions)#np.argmax(predictions, axis=2)\n",
    "    fake_news = tokenizer.sequences_to_texts(fake_news)\n",
    "    \n",
    "    return fake_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator(dim):\n",
    "    \n",
    "    input_layer = Input(shape=[dim])\n",
    "    \n",
    "    x = Dense(4 * 64, input_shape=[dim])(input_layer)\n",
    "    \n",
    "    x = Reshape((4, 64))(x)\n",
    "    \n",
    "    x = Conv1D(64, kernel_size, padding=\"same\", activation=\"softmax\")(x)\n",
    "    x = Conv1D(64, kernel_size, padding=\"same\", activation=\"softmax\")(x)\n",
    "    #x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = UpSampling1D()(x)\n",
    "    \n",
    "    x = Conv1D(128, kernel_size, padding=\"same\", activation=\"softmax\")(x)\n",
    "    x = Conv1D(128, kernel_size, padding=\"same\", activation=\"softmax\")(x)\n",
    "    #x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = UpSampling1D()(x)\n",
    "    \n",
    "    x = Conv1D(256, kernel_size, padding=\"same\", activation=\"softmax\")(x)\n",
    "    x = Conv1D(256, kernel_size, padding=\"same\", activation=\"softmax\")(x)\n",
    "    #x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = UpSampling1D()(x)\n",
    "    \n",
    "    x = Conv1D(512, kernel_size, padding=\"same\", activation=\"softmax\")(x)\n",
    "    x = Conv1D(512, kernel_size, padding=\"same\", activation=\"softmax\")(x)\n",
    "    #x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = Conv1D(1024, kernel_size, padding=\"same\", activation=\"softmax\")(x)\n",
    "    x = Conv1D(1024, kernel_size, padding=\"same\", activation=\"softmax\")(x)\n",
    "    #x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(1024)(x)\n",
    "    \n",
    "    x = Dense(maxlen, activation=\"softmax\")(x)\n",
    "    \n",
    "    output_layer = Lambda(lambda x: x * max_features)(x)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=0.0005, beta_1=.5))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_discriminator():\n",
    "\n",
    "    input_layer = Input(shape=[maxlen])\n",
    "    \n",
    "    x = Lambda(lambda x: x / max_features)(input_layer)\n",
    "    \n",
    "    x = Dense(256)(x)\n",
    "    x = Reshape((256, 1))(x)\n",
    "    x = Conv1D(128, kernel_size, padding=\"same\")(x)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Conv1D(64, kernel_size, padding=\"same\")(x)\n",
    "    x = MaxPooling1D()(x)\n",
    "    #x = Dropout(0.1)(x)\n",
    "    x = Conv1D(32, kernel_size, padding=\"same\")(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    output_layer = Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=0.0002, beta_1=.5))\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_gan(generator, discriminator, latent_dim):\n",
    "    \n",
    "    input_layer = Input(shape=[latent_dim])\n",
    "    \n",
    "    x = generator(input_layer)\n",
    "    \n",
    "    output_layer = discriminator(x)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=0.0002, beta_1=.5))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 256, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 256, 128)          768       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 128, 64)           41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 64, 32)            10272     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 58,465\n",
      "Trainable params: 58,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 4, 128)            82048     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 4, 128)            82048     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 8, 256)            164096    \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 8, 256)            327936    \n",
      "_________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1 (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16, 512)           655872    \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16, 512)           1311232   \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 16, 1024)          2622464   \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16, 1024)          5243904   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                262160    \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 10,803,472\n",
      "Trainable params: 10,803,472\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = create_discriminator()\n",
    "generator = create_generator(latent_dim)\n",
    "gan = create_gan(generator, discriminator, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator_model, discriminator_model, gan_model, nb_epochs, batch_size):\n",
    "    discriminator_losses = []\n",
    "    \n",
    "    generator_losses = []\n",
    "    \n",
    "    for i in range(nb_epochs):\n",
    "\n",
    "        x_fake, y_fake = getFakeSamples(generator_model, latent_dim, batch_size)\n",
    "        x_real, y_real = getRealSamples(x_train, y_train, batch_size)\n",
    "        \n",
    "        discriminator_model.trainable = True\n",
    "\n",
    "        loss1 = discriminator_model.train_on_batch(x_real, y_real)\n",
    "        loss2 = discriminator_model.train_on_batch(x_fake, y_fake)\n",
    "        loss3 = (loss1 + loss2) / 2\n",
    "        \n",
    "        discriminator_model.trainable = False\n",
    "        \n",
    "        x_gan, y_gan = getLatentSamples(latent_dim, batch_size)        \n",
    "        \n",
    "        loss_gan = gan_model.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "        discriminator_losses.append(loss3)\n",
    "        \n",
    "        generator_losses.append(loss_gan)\n",
    "        \n",
    "        print(f\"Epoch {i}  ;  Discriminator loss : {loss3}   ;    Generator loss : {loss_gan}\", end=\"\\r\")\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\n\")\n",
    "            print(generateFakeNews(generator_model, 1))\n",
    "        \n",
    "    return discriminator_losses, generator_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shadow\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  ;  Discriminator loss : 0.6949530243873596   ;    Generator loss : 0.6951442360877991\n",
      "\n",
      "['all all all all all all all all all all all all all all all all']\n",
      "Epoch 100  ;  Discriminator loss : 0.4769939184188843   ;    Generator loss : 1.4329358339309692\n",
      "\n",
      "['republicans democrat muslim off syrian mexico political fake man one may deal campaign – – have']\n",
      "Epoch 200  ;  Discriminator loss : 0.42748600244522095   ;    Generator loss : 1.5123069286346436\n",
      "\n",
      "['are black was black jerusalem never threat americans gop against against against republican are state that']\n",
      "Epoch 300  ;  Discriminator loss : 0.43587526679039   ;    Generator loss : 1.5917423963546753118\n",
      "\n",
      "['white bill republican donald administration shut workers us up white trump’s clinton clinton white president not']\n",
      "Epoch 400  ;  Discriminator loss : 0.412104070186615   ;    Generator loss : 1.648822784423828168\n",
      "\n",
      "['house president iran should it’s because agencies why trump’s from his house about by house over']\n",
      "Epoch 500  ;  Discriminator loss : 0.3918578028678894   ;    Generator loss : 1.64846444129943852\n",
      "\n",
      "['about russia claims source chief racist possible campaign are from who about new watch by at']\n",
      "Epoch 600  ;  Discriminator loss : 0.40639644861221313   ;    Generator loss : 1.7729119062423706\n",
      "\n",
      "['watch state group passes talks congress call iran obama’s trump’s when be republican that clinton obama']\n",
      "Epoch 700  ;  Discriminator loss : 0.4383291006088257   ;    Generator loss : 1.71981215476989755\n",
      "\n",
      "['hillary out law secret into ” man senator fight former arrested obama’s twitter america government at']\n",
      "Epoch 800  ;  Discriminator loss : 0.4645273685455322   ;    Generator loss : 1.66467642784118653\n",
      "\n",
      "['be hillary no take china china leader first time americans candidate say fox sanders take says']\n",
      "Epoch 900  ;  Discriminator loss : 0.46615660190582275   ;    Generator loss : 1.6087057590484626\n",
      "\n",
      "['this house you an down russian party hillary’s two attacks poll want they it’s ted a']\n",
      "Epoch 1000  ;  Discriminator loss : 0.3971118927001953   ;    Generator loss : 1.6714067459106445\n",
      "\n",
      "[\"will as are back why party trump's arrested their attacks gun healthcare may twitter protest the\"]\n",
      "Epoch 1100  ;  Discriminator loss : 0.4128357768058777   ;    Generator loss : 1.70835793018341067\n",
      "\n",
      "['at is trump’s tax election fbi how hilariously muslim nuclear russian before senate down arrested for']\n",
      "Epoch 1200  ;  Discriminator loss : 0.37874507904052734   ;    Generator loss : 1.7675477266311646\n",
      "\n",
      "['and and watch north it democrats court politics donald chief media brexit state senate islamic of']\n",
      "Epoch 1300  ;  Discriminator loss : 0.3999202847480774   ;    Generator loss : 1.80645966529846207\n",
      "\n",
      "['s and about that it war her europe tax syria news most media vote day of']\n",
      "Epoch 1400  ;  Discriminator loss : 0.42943674325942993   ;    Generator loss : 1.7391120195388794\n",
      "\n",
      "['s at watch that russia supreme senate own eu being how sean off more women of']\n",
      "Epoch 1500  ;  Discriminator loss : 0.40413716435432434   ;    Generator loss : 1.7717162370681763\n",
      "\n",
      "['u clinton watch russia bill attacks senate bernie military man black calling nuclear may them video']\n",
      "Epoch 1600  ;  Discriminator loss : 0.3980603814125061   ;    Generator loss : 1.65259540081024175\n",
      "\n",
      "['s media his this russia or senate could claims pm korea immigration bid tweets sanders video']\n",
      "Epoch 1700  ;  Discriminator loss : 0.4079171419143677   ;    Generator loss : 1.72728943824768075\n",
      "\n",
      "['a syria watch president who can court law face us north would clinton’s gop party in']\n",
      "Epoch 1800  ;  Discriminator loss : 0.38785815238952637   ;    Generator loss : 1.8119585514068604\n",
      "\n",
      "['says opposition his will was man against if can’t muslim who ” shot donald campaign in']\n",
      "Epoch 1900  ;  Discriminator loss : 0.3993561565876007   ;    Generator loss : 1.81755280494689945\n",
      "\n",
      "['obama iranian over from against leader he him pm has white court killed who election trump']\n",
      "Epoch 2000  ;  Discriminator loss : 0.38368791341781616   ;    Generator loss : 1.9027583599090576\n",
      "\n",
      "[\"from counsel after says he trump's new be anti who house be during be out trump\"]\n",
      "Epoch 2100  ;  Discriminator loss : 0.38110262155532837   ;    Generator loss : 1.9282084703445435\n",
      "\n",
      "['just advisor is with be more hillary will him election house clinton ” are out trump']\n",
      "Epoch 2200  ;  Discriminator loss : 0.37134701013565063   ;    Generator loss : 1.9217795133590698\n",
      "\n",
      "['speech steps as is who one trump’s president donald into white just tweets plan court in']\n",
      "Epoch 2300  ;  Discriminator loss : 0.40577399730682373   ;    Generator loss : 1.8410235643386842\n",
      "\n",
      "['arrested face as says he anti trump’s his against asks president clinton down french breaking of']\n",
      "Epoch 2400  ;  Discriminator loss : 0.3994927406311035   ;    Generator loss : 1.89540469646453865\n",
      "\n",
      "['americans foreign by and russia calls white over who lives not watch korea front against video']\n",
      "Epoch 2500  ;  Discriminator loss : 0.38598084449768066   ;    Generator loss : 1.8877906799316406\n",
      "\n",
      "['former during will a republicans iran clinton as bill tries hillary over state economic are in']\n",
      "Epoch 2600  ;  Discriminator loss : 0.3630163371562958   ;    Generator loss : 1.96756911277771652\n",
      "\n",
      "['north vote will on congress government watch and not everyone as says not city white trump']\n",
      "Epoch 2700  ;  Discriminator loss : 0.387167751789093   ;    Generator loss : 1.995057821273803768\n",
      "\n",
      "['about clinton as video they news obama on as read and the after would obama to']\n",
      "Epoch 2800  ;  Discriminator loss : 0.36969372630119324   ;    Generator loss : 1.9911978244781494\n",
      "\n",
      "['after by says in government north says of after pathetic s for and what and to']\n",
      "Epoch 2900  ;  Discriminator loss : 0.357502818107605   ;    Generator loss : 2.037545919418335525\n",
      "\n",
      "['and obama and in they are says video obama allowing a of s vote a to']\n",
      "Epoch 3000  ;  Discriminator loss : 0.3525044023990631   ;    Generator loss : 2.12264442443847665\n",
      "\n",
      "['a after a in makes him obama video about point says for a you a trump']\n",
      "Epoch 3100  ;  Discriminator loss : 0.372381329536438   ;    Generator loss : 2.059745073318481416\n",
      "\n",
      "['u says with trump soldiers syria his video republican epic watch of a north with trump']\n",
      "Epoch 3200  ;  Discriminator loss : 0.34659647941589355   ;    Generator loss : 2.1226358413696293\n",
      "\n",
      "['on s at trump boost states her video chief director you of a are says for']\n",
      "Epoch 3300  ;  Discriminator loss : 0.4113426208496094   ;    Generator loss : 1.97525644302368168\n",
      "\n",
      "['of the by trump city debate hillary’s in bush now move for says republican not new']\n",
      "Epoch 3400  ;  Discriminator loss : 0.4190407693386078   ;    Generator loss : 1.90619468688964847\n",
      "\n",
      "['in of this to goes could post trump made wants too for and out vote security']\n",
      "Epoch 3500  ;  Discriminator loss : 0.37525641918182373   ;    Generator loss : 1.9295378923416138\n",
      "\n",
      "['in video one to military war them trump now gun florida on and trump’s attack ep']\n",
      "Epoch 3600  ;  Discriminator loss : 0.38007470965385437   ;    Generator loss : 1.9922196865081787\n",
      "\n",
      "['in video wall to brexit plan get trump our war sources for a white plan chair']\n",
      "Epoch 3700  ;  Discriminator loss : 0.34707382321357727   ;    Generator loss : 1.9769723415374756\n",
      "\n",
      "['trump in wife to tells tweets man trump like iran poll of s new pick won’t']\n",
      "Epoch 3800  ;  Discriminator loss : 0.37398505210876465   ;    Generator loss : 1.9315321445465088\n",
      "\n",
      "['in in shows to top senator man trump racist china man of a new funds democrats']\n",
      "Epoch 3900  ;  Discriminator loss : 0.371518075466156   ;    Generator loss : 1.920803189277649303\n",
      "\n",
      "['in of democrats trump chief sanctions goes in national first pm on obama trump’s hack korea']\n",
      "Epoch 4000  ;  Discriminator loss : 0.3794656991958618   ;    Generator loss : 1.96233856678009033\n",
      "\n",
      "['of on senate in all texas year of department before south a clinton republican repeal who']\n",
      "Epoch 4100  ;  Discriminator loss : 0.37387096881866455   ;    Generator loss : 1.9609528779983524\n",
      "\n",
      "['for s it video plan 1 cnn the 000 post make from no tax votes president']\n",
      "Epoch 4200  ;  Discriminator loss : 0.3655082583427429   ;    Generator loss : 1.97636437416076666\n",
      "\n",
      "['the with hillary for us would fbi with latest interview ban out visit law mayor his']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4300  ;  Discriminator loss : 0.34346336126327515   ;    Generator loss : 1.9634989500045776\n",
      "\n",
      "['the says as on police may muslim after email officials attack senate comments leader judge as']\n",
      "Epoch 4400  ;  Discriminator loss : 0.35270529985427856   ;    Generator loss : 2.0542051792144775\n",
      "\n",
      "['for and is on her breaking gop at democratic sanders calls no romney may police with']\n",
      "Epoch 4500  ;  Discriminator loss : 0.3376949727535248   ;    Generator loss : 2.19439697265625713\n",
      "\n",
      "['of s with on who state gop over ted us court party comes you against a']\n",
      "Epoch 4600  ;  Discriminator loss : 0.3728148937225342   ;    Generator loss : 2.01894211769104062\n",
      "\n",
      "['video u with the bill election tweets just push muslim court kill strike against republican a']\n",
      "Epoch 4700  ;  Discriminator loss : 0.3788793385028839   ;    Generator loss : 2.07686066627502446\n",
      "\n",
      "['in for and u will state america news investigation against who picks officials clinton this u']\n",
      "Epoch 4800  ;  Discriminator loss : 0.3642693758010864   ;    Generator loss : 2.03571128845214846\n",
      "\n",
      "['trump of and with his him than presidential caught russia are fighting border his russia the']\n",
      "Epoch 4900  ;  Discriminator loss : 0.3469521105289459   ;    Generator loss : 2.05847358703613372\n",
      "\n",
      "['to in and from over senate push ambassador get new state students twitter at russia the']\n",
      "Epoch 5000  ;  Discriminator loss : 0.3598829507827759   ;    Generator loss : 2.08303165435791443\n",
      "\n",
      "['to trump s clinton is that criminal yet russian at up military have and he for']\n",
      "Epoch 5100  ;  Discriminator loss : 0.35003751516342163   ;    Generator loss : 2.2159821987152177\n",
      "\n",
      "['to the has a trump’s opens huge vote and bill government was u clinton of']\n",
      "Epoch 5200  ;  Discriminator loss : 0.3304177522659302   ;    Generator loss : 2.23313140869140627\n",
      "\n",
      "['to the first and president desperate see donald with against gets her s be of']\n",
      "Epoch 5300  ;  Discriminator loss : 0.36261484026908875   ;    Generator loss : 2.2066230773925786\n",
      "\n",
      "['to trump s set obama bill decision refugee china over america cnn may at court for']\n",
      "Epoch 5400  ;  Discriminator loss : 0.37768837809562683   ;    Generator loss : 2.2224562168121347\n",
      "\n",
      "['trump of u we hillary has healthcare busted minister election its supreme syria are senate for']\n",
      "Epoch 5500  ;  Discriminator loss : 0.32792922854423523   ;    Generator loss : 2.2246472835540775\n",
      "\n",
      "['in the on campaign white you their most their n 12 should man russian was of']\n",
      "Epoch 5600  ;  Discriminator loss : 0.36311766505241394   ;    Generator loss : 2.2173097133636475\n",
      "\n",
      "['video and for against it – obama’s old into saudi act would can claims you video']\n",
      "Epoch 5700  ;  Discriminator loss : 0.36847972869873047   ;    Generator loss : 2.1744680404663086\n",
      "\n",
      "['of with of clinton he people donald hillary’s calls bernie conservative fbi democrat citizens her in']\n",
      "Epoch 5800  ;  Discriminator loss : 0.35430407524108887   ;    Generator loss : 2.2502803802490234\n",
      "\n",
      "['video a video his white americans against being state minister factbox tax iran hannity court trump']\n",
      "Epoch 5900  ;  Discriminator loss : 0.3617122173309326   ;    Generator loss : 2.15404486656188962\n",
      "\n",
      "['video s video hillary white mike against wow this attack cnn donald tax missile korea trump']\n",
      "Epoch 6000  ;  Discriminator loss : 0.36764633655548096   ;    Generator loss : 2.2773265838623047\n",
      "\n",
      "['in on in watch his game russia old will republicans back election court must anti trump']\n",
      "Epoch 6100  ;  Discriminator loss : 0.3415297567844391   ;    Generator loss : 2.28426361083984387\n",
      "\n",
      "['trump on video president new dems election room clinton may speech news him or sanders trump']\n",
      "Epoch 6200  ;  Discriminator loss : 0.3618764579296112   ;    Generator loss : 2.16634535789489754\n",
      "\n",
      "['to video of state about f breaking puerto clinton republicans it’s campaign you year yet trump']\n",
      "Epoch 6300  ;  Discriminator loss : 0.34657302498817444   ;    Generator loss : 2.2760183811187744\n",
      "\n",
      "['to in video that as wants her attacks hillary news america how north they taxpayer trump']\n",
      "Epoch 6400  ;  Discriminator loss : 0.34733128547668457   ;    Generator loss : 2.2596950531005865\n",
      "\n",
      "['to in video up obama but was under new tax america how north obama’s companies trump']\n",
      "Epoch 6500  ;  Discriminator loss : 0.3231474459171295   ;    Generator loss : 2.48230910301208538\n",
      "\n",
      "['to in video republican at leader breaking meet just n it’s campaign him may until trump']\n",
      "Epoch 6600  ;  Discriminator loss : 0.3549154996871948   ;    Generator loss : 2.53996181488037116\n",
      "\n",
      "['trump in of court by security tax lawyer donald show our law have democrats repeal trump']\n",
      "Epoch 6700  ;  Discriminator loss : 0.3560788035392761   ;    Generator loss : 2.15101599693298346\n",
      "\n",
      "['trump video video be from off was decision gets planned putin us how gets big trump']\n",
      "Epoch 6800  ;  Discriminator loss : 0.3439696431159973   ;    Generator loss : 2.38847827911376953\n",
      "\n",
      "['trump in in as is police president being war nothing during calls court police but to']\n",
      "Epoch 6900  ;  Discriminator loss : 0.3345998525619507   ;    Generator loss : 2.32511115074157724\n",
      "\n",
      "['in in in after with vote not senator meeting super fbi media election tax fbi to']\n",
      "Epoch 7000  ;  Discriminator loss : 0.36892446875572205   ;    Generator loss : 2.4890477657318115\n",
      "\n",
      "['in in in from with was just senator afghanistan home during tweets donald vote democrats to']\n",
      "Epoch 7100  ;  Discriminator loss : 0.3268151581287384   ;    Generator loss : 2.45174574851989756\n",
      "\n",
      "['trump trump in from a out trump’s n veterans can democrats first state russia more to']\n",
      "Epoch 7200  ;  Discriminator loss : 0.33234861493110657   ;    Generator loss : 2.3071858882904053\n",
      "\n",
      "['trump trump in watch s trump’s this fbi perfectly war former mexico state just republicans to']\n",
      "Epoch 7300  ;  Discriminator loss : 0.36358970403671265   ;    Generator loss : 2.3379690647125244\n",
      "\n",
      "['trump to video are a will has it’s pay russian war stay was will china to']\n",
      "Epoch 7400  ;  Discriminator loss : 0.3228868842124939   ;    Generator loss : 2.63513016700744635\n",
      "\n",
      "['trump to video republican u by election an political news government migrant that over gop to']\n",
      "Epoch 7500  ;  Discriminator loss : 0.3470994532108307   ;    Generator loss : 2.66667938232421887\n",
      "\n",
      "['in to of that s over has being ex vote twitter borders republican from gop to']\n",
      "Epoch 7600  ;  Discriminator loss : 0.3493878245353699   ;    Generator loss : 2.69070386886596755\n",
      "\n",
      "['of to for against and about tax killed so tax putin illinois him house one to']\n",
      "Epoch 7700  ;  Discriminator loss : 0.33036303520202637   ;    Generator loss : 2.7742366790771484\n",
      "\n",
      "['u to on donald says watch top hit day anti can’t key korea about china to']\n",
      "Epoch 7800  ;  Discriminator loss : 0.3471447825431824   ;    Generator loss : 2.70376992225646973\n",
      "\n",
      "['of to on this and at minister place minister state response your who obama media to']\n",
      "Epoch 7900  ;  Discriminator loss : 0.3661889433860779   ;    Generator loss : 2.64765262603759776\n",
      "\n",
      "['video to on new and after speech rnc eu russia nuclear sanders up is has to']\n",
      "Epoch 8000  ;  Discriminator loss : 0.29214200377464294   ;    Generator loss : 2.6369662284851074\n",
      "\n",
      "['video to the about obama at south ends chief state can can gop at korea to']\n",
      "Epoch 8100  ;  Discriminator loss : 0.30336716771125793   ;    Generator loss : 2.8271298408508365\n",
      "\n",
      "['for to is about that new rights children obamacare – candidate did visit will deal to']\n",
      "Epoch 8200  ;  Discriminator loss : 0.355596661567688   ;    Generator loss : 2.678303003311157235\n",
      "\n",
      "['for trump by obama back watch get healthcare can no probe an signs new media to']\n",
      "Epoch 8300  ;  Discriminator loss : 0.34503740072250366   ;    Generator loss : 2.7779083251953125\n",
      "\n",
      "['of trump clinton and would by china congress would vote china senator pastor about was to']\n",
      "Epoch 8400  ;  Discriminator loss : 0.35205963253974915   ;    Generator loss : 3.2160844802856445\n",
      "\n",
      "['of trump gets and justice about anti back but vote no party percent watch election to']\n",
      "Epoch 8500  ;  Discriminator loss : 0.3324697017669678   ;    Generator loss : 2.86451244354248056\n",
      "\n",
      "['from trump change u issue about has vote back him north media trade over it']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8600  ;  Discriminator loss : 0.3768281042575836   ;    Generator loss : 2.85171222686767618\n",
      "\n",
      "['he trump canada a 11 over calls him muslim russia that has wow after trump’s']\n",
      "Epoch 8700  ;  Discriminator loss : 0.37212449312210083   ;    Generator loss : 2.8538997173309326\n",
      "\n",
      "['out trump friend is mayor as what election tax trump’s up north official says will']\n",
      "Epoch 8800  ;  Discriminator loss : 0.35091084241867065   ;    Generator loss : 2.8998608589172363\n",
      "\n",
      "['watch trump appeal as ex after ” up her about it this during s about']\n",
      "Epoch 8900  ;  Discriminator loss : 0.3624451160430908   ;    Generator loss : 2.92166543006896978\n",
      "\n",
      "['at trump 2017 watch brexit says people out that as president president ” the from']\n",
      "Epoch 9000  ;  Discriminator loss : 0.31409257650375366   ;    Generator loss : 3.1753926277160645\n",
      "\n",
      "['as trump asylum russia fox is illegal it republican obama be clinton china the from']\n",
      "Epoch 9100  ;  Discriminator loss : 0.37109285593032837   ;    Generator loss : 2.7585203647613525\n",
      "\n",
      "['at in violent judge eu is staff bill that says bill will down on from']\n",
      "Epoch 9200  ;  Discriminator loss : 0.3285226821899414   ;    Generator loss : 3.38951110839843757\n",
      "\n",
      "['for trump your she her the ground his hillary on will obama up video with']\n",
      "Epoch 9300  ;  Discriminator loss : 0.30494076013565063   ;    Generator loss : 3.2673034667968758\n",
      "\n",
      "['in trump party hillary’s just for diplomat as from of about a not in u']\n",
      "Epoch 9400  ;  Discriminator loss : 0.31311559677124023   ;    Generator loss : 3.5737843513488774\n",
      "\n",
      "['trump to calls time new video morning is at video by u house trump the']\n",
      "Epoch 9500  ;  Discriminator loss : 0.29244691133499146   ;    Generator loss : 3.4449443817138676\n",
      "\n",
      "['trump to against host house video shoots with obama in by the as trump on']\n",
      "Epoch 9600  ;  Discriminator loss : 0.3355836868286133   ;    Generator loss : 3.35017633438110353\n",
      "\n",
      "['to trump it must as in policies and obama in about on after trump on']\n",
      "Epoch 9700  ;  Discriminator loss : 0.33780768513679504   ;    Generator loss : 4.0104641914367685\n",
      "\n",
      "['to trump clinton post obama in sales s as trump new for is to on']\n",
      "Epoch 9800  ;  Discriminator loss : 0.31989648938179016   ;    Generator loss : 3.5235540866851807\n",
      "\n",
      "['to trump new islamic is in shoots u about trump it for says to on']\n",
      "Epoch 9900  ;  Discriminator loss : 0.27606692910194397   ;    Generator loss : 3.4934329986572266\n",
      "\n",
      "['to video his can is in cause u just trump muslim for says trump the']\n",
      "Epoch 10000  ;  Discriminator loss : 0.37875786423683167   ;    Generator loss : 3.720008611679077\n",
      "\n",
      "['to says watch democrats is in tucker u tweets in economic the says trump with']\n",
      "Epoch 10100  ;  Discriminator loss : 0.36190032958984375   ;    Generator loss : 3.6321351528167725\n",
      "\n",
      "['to gets after korea s in city for democrats trump thursday of the to s']\n",
      "Epoch 10200  ;  Discriminator loss : 0.5777754783630371   ;    Generator loss : 4.43841457366943493\n",
      "\n",
      "['life with gop u in time for people to economy of on to the']\n",
      "Epoch 10300  ;  Discriminator loss : 0.3875070810317993   ;    Generator loss : 4.65293025970459975\n",
      "\n",
      "['embassy u watch for trump democrats video refugees to look video of to of']\n",
      "Epoch 10400  ;  Discriminator loss : 0.5603387355804443   ;    Generator loss : 6.60821151733398445\n",
      "\n",
      "['assault of s video to north trump they’re to fire in in to in']\n",
      "Epoch 10500  ;  Discriminator loss : 0.3870195746421814   ;    Generator loss : 5.46011352539062555\n",
      "\n",
      "['facebook in video trump to about to 14 man trump trump to']\n",
      "Epoch 10600  ;  Discriminator loss : 0.4542163610458374   ;    Generator loss : 5.40884590148925875\n",
      "\n",
      "['when to to to s dirty north to to']\n",
      "Epoch 10700  ;  Discriminator loss : 0.36858120560646057   ;    Generator loss : 5.5611333847045955\n",
      "\n",
      "['breaking to to to for drone watch']\n",
      "Epoch 10800  ;  Discriminator loss : 0.5571384429931641   ;    Generator loss : 6.40457534790039175\n",
      "\n",
      "['will video karma says']\n",
      "Epoch 10900  ;  Discriminator loss : 0.613511323928833   ;    Generator loss : 6.616530418395996145\n",
      "\n",
      "['obama trump flood u']\n",
      "Epoch 11000  ;  Discriminator loss : 0.6282238960266113   ;    Generator loss : 5.93616390228271595\n",
      "\n",
      "['a trump ousted for']\n",
      "Epoch 11100  ;  Discriminator loss : 0.47687727212905884   ;    Generator loss : 4.9655609130859375\n",
      "\n",
      "['on to comey’s video']\n",
      "Epoch 11200  ;  Discriminator loss : 0.47462889552116394   ;    Generator loss : 5.2746253013610845\n",
      "\n",
      "['of to banks in']\n",
      "Epoch 11300  ;  Discriminator loss : 0.3733317255973816   ;    Generator loss : 4.29237031936645555\n",
      "\n",
      "['video to haley in']\n",
      "Epoch 11400  ;  Discriminator loss : 0.426312118768692   ;    Generator loss : 4.792491912841797895\n",
      "\n",
      "['in to standing trump']\n",
      "Epoch 11500  ;  Discriminator loss : 0.40504252910614014   ;    Generator loss : 4.9942040443420415\n",
      "\n",
      "['in to peninsula trump']\n",
      "Epoch 11600  ;  Discriminator loss : 0.46570202708244324   ;    Generator loss : 4.9699769020080575\n",
      "\n",
      "['trump to create to']\n",
      "Epoch 11700  ;  Discriminator loss : 0.44015610218048096   ;    Generator loss : 4.7908577919006355\n",
      "\n",
      "['trump create to']\n",
      "Epoch 11800  ;  Discriminator loss : 0.40191012620925903   ;    Generator loss : 4.4643850326538095\n",
      "\n",
      "['trump direct to']\n",
      "Epoch 11900  ;  Discriminator loss : 0.8193137645721436   ;    Generator loss : 6.96855163574218755\n",
      "\n",
      "['to direct to']\n",
      "Epoch 12000  ;  Discriminator loss : 0.39382559061050415   ;    Generator loss : 4.2061057090759285\n",
      "\n",
      "['to direct to']\n",
      "Epoch 12100  ;  Discriminator loss : 0.40318992733955383   ;    Generator loss : 6.1352868080139165\n",
      "\n",
      "['to putting to']\n",
      "Epoch 12200  ;  Discriminator loss : 0.4440584182739258   ;    Generator loss : 6.8449897766113281\n",
      "\n",
      "['to putting to']\n",
      "Epoch 12300  ;  Discriminator loss : 0.8888627886772156   ;    Generator loss : 7.3576316833496094\n",
      "\n",
      "['to putting to']\n",
      "Epoch 12400  ;  Discriminator loss : 0.6384584903717041   ;    Generator loss : 4.66719818115234455\n",
      "\n",
      "['to putting to']\n",
      "Epoch 12500  ;  Discriminator loss : 0.5678080916404724   ;    Generator loss : 7.4155459403991703\n",
      "\n",
      "['to putting to']\n",
      "Epoch 12600  ;  Discriminator loss : 1.0725661516189575   ;    Generator loss : 12.3102474212646485\n",
      "\n",
      "['to putting to']\n",
      "Epoch 12700  ;  Discriminator loss : 0.6032670736312866   ;    Generator loss : 7.9075131416320828\n",
      "\n",
      "['to putting']\n",
      "Epoch 12800  ;  Discriminator loss : 0.6985818147659302   ;    Generator loss : 7.43642044067382835\n",
      "\n",
      "['to putting']\n",
      "Epoch 12900  ;  Discriminator loss : 0.7285388112068176   ;    Generator loss : 8.48075389862060555\n",
      "\n",
      "['to putting']\n",
      "Epoch 12907  ;  Discriminator loss : 0.6575140357017517   ;    Generator loss : 8.97976016998291295\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4c8b8ecca24a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-537aadead5da>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(generator_model, discriminator_model, gan_model, nb_epochs, batch_size)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mx_fake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFakeSamples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mx_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetRealSamples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-f64ec278eb3b>\u001b[0m in \u001b[0;36mgetFakeSamples\u001b[1;34m(generator, latent_dim, n)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mlatent_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \"\"\"\n\u001b[1;32m-> 1605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DL, GL = train(generator, discriminator, gan, 15000, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_points = generate_latent_points(latent_dim, 10)\n",
    "predictions = generator.predict(few_points)\n",
    "\n",
    "print(predictions[3])\n",
    "\n",
    "#predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "print(predictions[3])\n",
    "\n",
    "print(tokenizer.sequences_to_texts(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# art plastique du turfu featuring le poto matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-0b66da677d1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DL' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(1, 2)\n",
    "figure.set_size_inches(20,10)\n",
    "\n",
    "ax[0].plot(DL)\n",
    "\n",
    "ax[1].plot(GL)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = dataframe.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = to_predict[\"title\"]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = to_predict[\"label\"]\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save(\"generator.h5\")\n",
    "discriminator.save(\"discriminator.h5\")\n",
    "tokenizerJSON = tokenizer.to_json()\n",
    "\n",
    "with open(\"gan_tokenizer.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(tokenizerJSON, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
